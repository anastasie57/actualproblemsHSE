{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c678e33-7efc-47da-bd84-890daf4b5beb",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "Имплементируйте алгоритм Леска (описание есть в семинаре) и оцените качество его работы на датасете `data/corpus_wsd_50k.txt`\n",
    "\n",
    "В качестве метрики близости вы должны попробовать два подхода:\n",
    "\n",
    "1) Jaccard score на множествах слов (определений и контекста)\n",
    "2) Cosine distance на эмбедингах sentence_transformers\n",
    "\n",
    "В качестве метрики используйте accuracy (% правильных ответов). Предсказывайте только многозначные слова в датасете\n",
    "\n",
    "Контекст вы можете определить самостоятельно (окно вокруг целевого слова или все предложение). Также можете поэкспериментировать с предобработкой для обоих методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153a4330-4140-4507-a743-18264a8ae784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aomak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eca95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = []\n",
    "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4ccba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jaccard(definition, context):\n",
    "    intersection = (set(definition.split()) & set(context.split()))\n",
    "    union = (set(definition.split()) | set(context.split()))\n",
    "    jaccard =  len(intersection) / len(union)\n",
    "    return jaccard\n",
    "\n",
    "def lesk_algorithm_jaccard(meaning, context):\n",
    "    the_word = re.split('%', meaning)[0]\n",
    "    definitions = {}\n",
    "    for synset in wn.synsets(the_word):\n",
    "        definitions[synset.definition()] = find_jaccard(synset.definition(), context)\n",
    "    max_one = [0, '']\n",
    "    for definition in definitions:\n",
    "        if definitions[definition] > max_one[0]:\n",
    "            max_one[0] = definitions[definition]\n",
    "            max_one[1] = definition\n",
    "    return max_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c6ab413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224077061268043\n"
     ]
    }
   ],
   "source": [
    "correct_definitions = 0\n",
    "sum_of_words = 0\n",
    "for sent in corpus_wsd:\n",
    "    if len(sent) > 1:\n",
    "        context = ' '.join([word[2] for word in sent])\n",
    "        \n",
    "        for word in sent:\n",
    "            if '%' in word[0]:\n",
    "                context = context.replace(word[2], '_')\n",
    "                lesk_definition = lesk_algorithm_jaccard(word[0], context)\n",
    "                if lesk_definition[1] == wn.lemma_from_key(word[0]).synset().definition():\n",
    "                    correct_definitions+=1\n",
    "                sum_of_words+=1\n",
    "\n",
    "print(correct_definitions/sum_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efde9a-af0b-4c94-bfd0-249e7054562f",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "Попробуйте разные алгоритмы кластеризации на датасете - `https://github.com/nlpub/russe-wsi-kit/blob/initial/data/main/wiki-wiki/train.csv`\n",
    "\n",
    "Используйте код из семинара как основу. Используйте ARI как метрику качества.\n",
    "\n",
    "Попробуйте все 4 алгоритма кластеризации, про которые говорилось на семинаре. Для каждого из алгоритмов попробуйте настраивать гиперпараметры (посмотрите их в документации). Прогоните как минимум 5 экспериментов (не обязательно успешных) с разными параметрами на каждый алгоритме кластеризации и оцените: качество кластеризации, скорость работы, интуитивность параметров.\n",
    "\n",
    "Помимо этого также выберите 1 дополнительный алгоритм кластеризации отсюда - https://scikit-learn.org/stable/modules/clustering.html , опишите своими словами принцип его работы  и проделайте аналогичные эксперименты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bef3e-1af7-4ce2-b43a-dfef282050f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
